---
layout: post
title:  "spark" 
categories: 总结
tags: spark 
author: liujunwu
excerpt: mac安装spark（Hadoop伪分布式下）
mathjax: true
---

## 安装spark
1 . 去官网下载spark：

> http://spark.apache.org/downloads.html 

本人下载的版本是：spark-2.3.2-bin-hadoop2.7.tar,然后解压，移动到/usr/local/Cellar/ 下，（与Hadoop放在一起）移动时可以更改一下名字，变为spark-2.3.7

2 .  在当前目录下打开终端，进入到spark-2.3.7目录下，输入命令 sbin/start-master.sh

​	在浏览器输入localhost：8080，就可以打开spark的画面了。

3 . 执行命令 pip3 install pyspark 在python3下安装pyspark

4 . 设置环境变量

> vi ~/.bash_profile
>
> export SPARK_HOME=/usr/local/Cellar/spark2.3.7
>
> export PATH=\$PATH:$SPARK_HOME/bin
>
> source ~/.bash_profile. 是环境变量生效

5 . 在终端输入pyspark，就能看到spark的界面了。

