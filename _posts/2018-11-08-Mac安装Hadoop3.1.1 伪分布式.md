---
layout: post
title:  "Mac安装Hadoop3.1.1" 
categories: 总结
tags: Hadoop3.1.1伪分布式
author: liujunwu
excerpt: Mac安装Hadoop3.1.1伪分布式
mathjax: true
---

## Mac 安装Hadoop3.1.1 伪分布式

1. 安装Java：

   brew install java 即可

2. 设置ssh：

   - 打开系统便好设置，点击“共享”，勾选左侧远程登录，右侧选择所有用户，

   - 打开终端，依次执行命令`ssh-keygen -t rsa -P ''`，之后一路`enter`键，当然如果你之前已经执行过这样的语句，那过程中会提示是否要覆盖原有的key，输入`y`即可

   - 执行语句`cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys`用于授权你的公钥到本地可以无需密码实现登录

   - 在终端输入`ssh lcoalhost`就能够免密登录了，结果如下：

     ```python
     bogon:~ liujunwu$ ssh localhost
     Last login: Thu Nov  8 16:13:40 2018 from 127.0.0.1
     ```

   -  

3. 下载安装Hadoop

   * 查看java_home

   - ```python
     bogon:~ liujunwu$ /usr/libexec/java_home -V 
     1.8.0_181, x86_64:	"Java SE 8"	/Library/Java/JavaVirtualMachines/jdk1.8.0_181.jdk/Contents/Home 以安装的版本
     /Library/Java/JavaVirtualMachines/jdk1.8.0_181.jdk/Contents/Home 默认使用版本
     ```

   * brew install Hadoop 默认安装最新版本3.1.1 路径为/usr/local/Cellar/hadoop/3.1.1/

4 . 进入3.1.1>libexec >etc>Hadoop 在此处修改一些配置

   * 打开hadoop-env.sh，添加

     ```python
     export JAVA_HOME="/Library/Java/JavaVirtualMachines/jdk1.8.0_181.jdk/Contents/Home"
     ```

   * 设置core-site.xml

     ```python
     <configuration>
         <property>
             <name>fs.defaultFS</name>
             <value>hdfs://localhost:9000</value>
         </property>
     </configuration>
     ```

   * 设置hdfs-site.xml

     ```
     <configuration>
         <property>
             <name>dfs.replication</name>
             <value>1</value>
         </property>
     </configuration>
     ```

   * 设置mapred-site.xml

     ```
     <configuration>
         <property>
             <name>mapreduce.framework.name</name>
             <value>yarn</value>
         </property>
     </configuration>
     ```

   * 设置yarn-site.xml

     ```
     <configuration>
         <property>
             <name>yarn.nodemanager.aux-services</name>
             <value>mapreduce_shuffle</value>
         </property>
         <property>
             <name>yarn.nodemanager.env-whitelist</name>
       <value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME</value>
         </property>
     </configuration>
     ```

5 . 终端处返回到上级Hadoop目录那，执行该命令，格式化hadoop目录（理解为刷新一下配置）

   * bin/hdfs namenode -format

6 . 启动所有服务

   * 进入到/usr/local/Cellar/hadoop/3.1.1/libexec 路径下，执行 sbin/start_all.sh 就会开启所有服务

7 . 检测

   * 打开localhost:8088 或者localhost:9870 即可看到服务已启动。

8 . 设置环境变量，不必每次跳到现在目录下启动Hadoop

   * vi  ~/.bash_profile 添加 
   * export  HADOOP_HOME=/usr/local/Cellar/hadoop/3.1.1/libexec 
   * export  PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin

9 . 设置好后

   * 运行时：start-all.sh  终止时 stop-all.sh 

10 . 设置环境变量出错后报‘bash:vi:command not found’错误：  

* 在命令行中输入：export PATH=/usr/bin:/usr/sbin:/bin:/sbin:/usr/X11R6/bin  这样可以保证命令行命令暂时可以使用。命令执行完之后不要关闭终端，继续下一步；
* 在命令行中输入 vi ~/.bash_profile 进入到环境变量中,更改自己原先设置的PATH；
* 执行 source ~/.bash_profile 使配置生效即可
* 如还是不行，重复即可